# Kaggle Competition for Machine Learning for Data Science

This paper describes the data processing, feature reduction, Random Forest model selection trough cross validation and finally presents the model with minimal prediction error on the HCRC (Human Communication Research Centre) Map Task corpus dataset. This study was conducted on a Spring 2016 Machine Learning course (COMS 4721) predictive modeling project  context where the final predictions were submitted to Kaggle for students competition. 
We attempted to reduce the feature dimensionality by applying a combination of descriptive statistics and feature research for a manual feature selection and Lasso Regression and PCA  as reduction algorithms. The manual feature selection turned out to be most successful for this task. After running a cross-validated random search our final model consisted of a Random Forest with 167 decision trees that obtained a prediction accuracy of 93.92% on the holdout dataset, 93.7% and 93.9% on the public and private Kaggle validation datasets respectively.
